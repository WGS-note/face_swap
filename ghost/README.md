[[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9851423)] [[Habr](https://habr.com/ru/company/sberbank/blog/645919/)]

# ğŸ‘» GHOST: Generative High-fidelity One Shot Transfer 

Our paper ["GHOSTâ€”A New Face Swap Approach for Image and Video Domains"](https://ieeexplore.ieee.org/abstract/document/9851423) has been published on IEEE Xplore.

<p align="left">
  Google Colab Demo
</p>
<p align="left">
  <a href="https://colab.research.google.com/drive/1B-2JoRxZZwrY2eK_E7TB5VYcae3EjQ1f">
  <img src="https://colab.research.google.com/assets/colab-badge.svg"/>
  </a>
</p>

## GHOST Ethics 

> Deepfake stands for a face swapping algorithm where the source and target can be an image or a video. Researchers have investigated sophisticated generative adversarial networks (GAN), autoencoders, and other approaches to establish precise and robust algorithms for face swapping. However, the achieved results are far from perfect in terms of human and visual evaluation. In this study, we propose a new one-shot pipeline for image-to-image and image-to-video face swap solutions - GHOST (Generative High-fidelity One Shot Transfer).

Deepfakeæ˜¯ä¸€ç§äººè„¸äº¤æ¢ç®—æ³•ï¼Œæºå’Œç›®æ ‡å¯ä»¥æ˜¯å›¾åƒæˆ–è§†é¢‘ã€‚ç ”ç©¶äººå‘˜ç ”ç©¶äº†å¤æ‚çš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)ã€è‡ªåŠ¨ç¼–ç å™¨å’Œå…¶ä»–æ–¹æ³•ï¼Œä»¥å»ºç«‹ç²¾ç¡®å’Œå¥å£®çš„äººè„¸äº¤æ¢ç®—æ³•ã€‚ç„¶è€Œï¼Œæ‰€å–å¾—çš„ç»“æœåœ¨äººä¸è§†è§‰è¯„ä»·æ–¹é¢è¿˜è¿œè¿œä¸å¤Ÿå®Œå–„ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„ä¸€æ¬¡æ€§ç®¡é“ï¼Œç”¨äºå›¾åƒåˆ°å›¾åƒå’Œå›¾åƒåˆ°è§†é¢‘çš„äººè„¸äº¤æ¢è§£å†³æ–¹æ¡ˆ- GHOSTï¼ˆç”Ÿæˆé«˜ä¿çœŸçš„ä¸€ä¸ªé•œå¤´è½¬ç§»ï¼‰

> Deep fake synthesis methods have been improved a lot in quality in recent years. The research solutions were wrapped in easy-to-use API, software and different plugins for people with a little technical knowledge. As a result, almost anyone is able to make a deepfake image or video by just doing a short list of simple operations. At the same time, a lot of people with malicious intent are able to use this technology in order to produce harmful content. High distribution of such a content over the web leads to caution, disfavor and other negative feedback to deepfake synthesis or face swap research.

è¿‘å¹´æ¥ï¼Œæ·±åº¦å‡ä½“åˆæˆæ–¹æ³•åœ¨è´¨é‡ä¸Šæœ‰äº†å¾ˆå¤§çš„æ”¹è¿›ã€‚ç ”ç©¶è§£å†³æ–¹æ¡ˆåŒ…è£…åœ¨æ˜“äºä½¿ç”¨çš„APIã€è½¯ä»¶å’Œä¸åŒçš„æ’ä»¶ä¸­ï¼Œé€‚åˆæœ‰ä¸€ç‚¹æŠ€æœ¯çŸ¥è¯†çš„äººã€‚å› æ­¤ï¼Œå‡ ä¹ä»»ä½•äººéƒ½å¯ä»¥é€šè¿‡åšä¸€äº›ç®€å•çš„æ“ä½œæ¥åˆ¶ä½œdeepfakeå›¾åƒæˆ–è§†é¢‘ã€‚ä¸æ­¤åŒæ—¶ï¼Œè®¸å¤šæ€€æœ‰æ¶æ„çš„äººèƒ½å¤Ÿåˆ©ç”¨è¿™é¡¹æŠ€æœ¯æ¥åˆ¶ä½œæœ‰å®³çš„å†…å®¹ã€‚è¿™ç§å†…å®¹åœ¨ç½‘ç»œä¸Šçš„å¤§é‡ä¼ æ’­å¯¼è‡´äº†å¯¹æ·±åº¦é€ å‡åˆæˆæˆ–æ¢è„¸ç ”ç©¶çš„è°¨æ…ã€ä¸å–œæ¬¢å’Œå…¶ä»–è´Ÿé¢åé¦ˆ

> As a group of researchers, we are not trying to denigrate celebrities and statesmen or to demean anyone. We are computer vision researchers, we are engineers, we are activists, we are hobbyists, we are human beings. To this end, we feel that it's time to come out with a standard statement of what this technology is and isn't as far as us researchers are concerned.

ä½œä¸ºä¸€ç»„ç ”ç©¶äººå‘˜ï¼Œæˆ‘ä»¬å¹¶ä¸æ˜¯è¦è¯‹æ¯åäººå’Œæ”¿æ²»å®¶ï¼Œä¹Ÿä¸æ˜¯è¦è´¬ä½ä»»ä½•äººã€‚æˆ‘ä»¬æ˜¯è®¡ç®—æœºè§†è§‰ç ”ç©¶äººå‘˜ï¼Œæˆ‘ä»¬æ˜¯å·¥ç¨‹å¸ˆï¼Œæˆ‘ä»¬æ˜¯æ´»åŠ¨å®¶ï¼Œæˆ‘ä»¬æ˜¯ä¸šä½™çˆ±å¥½è€…ï¼Œæˆ‘ä»¬æ˜¯äººç±»ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬è§‰å¾—æ˜¯æ—¶å€™æå‡ºä¸€ä¸ªæ ‡å‡†çš„å£°æ˜ï¼Œè¯´æ˜è¿™é¡¹æŠ€æœ¯æ˜¯ä»€ä¹ˆï¼Œå°±æˆ‘ä»¬ç ”ç©¶äººå‘˜è€Œè¨€ä¸æ˜¯ä»€ä¹ˆã€‚

* GHOSTä¸ç”¨äºåˆ›å»ºä¸é€‚å½“çš„å†…å®¹ã€‚GHOST is not for creating inappropriate content.
* GHOSTä¸å…è®¸åœ¨æœªç»åŒæ„çš„æƒ…å†µä¸‹æ›´æ¢é¢å­”ï¼Œä¹Ÿä¸å…è®¸éšè—å…¶ç”¨é€”ã€‚GHOST is not for changing faces without consent or with the intent of hiding its use.
* GHOSTä¸ç”¨äºä»»ä½•éæ³•ã€ä¸é“å¾·æˆ–å¯ç–‘çš„ç›®çš„ã€‚GHOST is not for any illicit, unethical, or questionable purposes.
* GHOSTçš„å­˜åœ¨æ˜¯ä¸ºäº†å®éªŒå’Œå‘ç°äººå·¥æ™ºèƒ½æŠ€æœ¯ï¼Œç”¨äºç¤¾ä¼šæˆ–æ”¿æ²»è¯„è®ºï¼Œç”¨äºç”µå½±ï¼Œä»¥åŠä»»ä½•é“å¾·å’Œåˆç†çš„ç”¨é€”ã€‚GHOST exists to experiment and discover AI techniques, for social or political commentary, for movies, and for any number of ethical and reasonable uses.

> We are very troubled by the fact that GHOST can be used for unethical and disreputable things. However, we support the development of tools and techniques that can be used ethically as well as provide education and experience in AI for anyone who wants to learn it hands-on. Now and further, we take a **zero-tolerance approach** and **total disregard** to anyone using this software for any unethical purposes and will actively discourage any such uses.

æˆ‘ä»¬å¯¹GHOSTå¯èƒ½è¢«ç”¨äºä¸é“å¾·å’Œä¸å…‰å½©çš„äº‹æƒ…æ„Ÿåˆ°éå¸¸å›°æ‰°ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬æ”¯æŒå¼€å‘å¯ä»¥åœ¨é“å¾·ä¸Šä½¿ç”¨çš„å·¥å…·å’ŒæŠ€æœ¯ï¼Œå¹¶ä¸ºä»»ä½•æƒ³è¦åŠ¨æ‰‹å­¦ä¹ äººå·¥æ™ºèƒ½çš„äººæä¾›äººå·¥æ™ºèƒ½æ–¹é¢çš„æ•™è‚²å’Œç»éªŒã€‚ç°åœ¨å’Œä»¥åï¼Œæˆ‘ä»¬é‡‡å–**é›¶å®¹å¿çš„æ–¹æ³•**å’Œ**å®Œå…¨æ— è§†**ä»»ä½•äººä½¿ç”¨æœ¬è½¯ä»¶å‡ºäºä»»ä½•ä¸é“å¾·çš„ç›®çš„ï¼Œå¹¶å°†ç§¯æé˜»æ­¢ä»»ä½•æ­¤ç±»ä½¿ç”¨


## Image Swap Results 
![](./examples/images/example1.png)

![](./examples/images/example2.png)



## Video Swap Results
<div>
<img src="./examples/videos/orig.webp" width="360"/>
<img src="./examples/videos/elon.webp" width="360"/>
<img src="./examples/videos/khabenskii.webp" width="360"/>
<img src="./examples/videos/mark.webp" width="360"/>
<div/>


## Installation

1. å…‹éš†è¿™ä¸ªå­˜å‚¨åº“ Clone this repository
  ```bash
  git clone https://github.com/sberbank-ai/sber-swap.git
  cd sber-swap
  git submodule init
  git submodule update
  ```
2. å®‰è£…ä¾èµ–åŒ… Install dependent packages
  ```bash
  pip install -r requirements.txt
  ```
  ```
  numpy
  -f https://download.pytorch.org/whl/torch_stable.html
  torch==1.6.0+cu101
  -f https://download.pytorch.org/whl/torch_stable.html
  torchvision==0.7.0+cu101
  opencv-python
  onnx==1.9.0
  onnxruntime-gpu==1.4.0
  mxnet-cu101mkl
  scikit-image
  insightface==0.2.1
  requests==2.25.1
  kornia==0.5.4
  dill
  wandb
  ```
  
  > If it is not possible to install onnxruntime-gpu, try onnxruntime instead  
  
  å¦‚æœæ— æ³•å®‰è£…onnxruntime-gpuï¼Œè¯·å°è¯•å®‰è£…onnxruntime
  
3. ä¸‹è½½æƒé‡ Download weights
  ```bash
  sh download_models.sh
  ```
## Usage
  1. Colab Demo or you can use jupyter notebook [SberSwapInference.ipynb](SberSwapInference.ipynb) locally
  2. è§†é¢‘æ¢è„¸ Face Swap On Video

>  Swap to one specific person in the video. You must set face from the target video (for example, crop from any frame).

åˆ‡æ¢åˆ°è§†é¢‘ä¸­çš„ä¸€ä¸ªäººã€‚ä½ å¿…é¡»ä»ç›®æ ‡è§†é¢‘è®¾ç½®é¢(ä¾‹å¦‚ï¼Œä»ä»»ä½•å¸§è£å‰ª)ã€‚

  ```bash
  python inference.py --source_paths {PATH_TO_IMAGE} --target_faces_paths {PATH_TO_IMAGE} --target_video {PATH_TO_VIDEO}
  ```
> Swap to many person in the video. You must set multiple faces for source and the corresponding multiple faces from the target video.

äº¤æ¢åˆ°è§†é¢‘ä¸­çš„è®¸å¤šäººã€‚å¿…é¡»ä¸ºæºè§†é¢‘è®¾ç½®å¤šä¸ªäººè„¸ï¼Œå¹¶ä»ç›®æ ‡è§†é¢‘ä¸­è®¾ç½®ç›¸åº”çš„å¤šä¸ªäººè„¸ã€‚

  ```bash
  python inference.py 
  --source_paths {PATH_TO_IMAGE PATH_TO_IMAGE ...} 
  --target_faces_paths {PATH_TO_IMAGE PATH_TO_IMAGE ...} --target_video {PATH_TO_VIDEO}
  ```
  3. å›¾ç‰‡æ¢è„¸ Face Swap On Image

> You may set the target face, and then source will be swapped on this person, or you may skip this parameter, and then source will be swapped on any person in the image.

ä½ å¯ä»¥è®¾ç½®ç›®æ ‡äººè„¸ï¼Œç„¶ååœ¨è¿™ä¸ªäººèº«ä¸Šäº¤æ¢æºï¼Œæˆ–è€…ä½ å¯ä»¥è·³è¿‡è¿™ä¸ªå‚æ•°ï¼Œç„¶ååœ¨å›¾åƒä¸­çš„ä»»ä½•ä¸€ä¸ªäººèº«ä¸Šäº¤æ¢æºã€‚

  ```bash
  python inference.py --target_path {PATH_TO_IMAGE} --image_to_image True
  ```

## Training

> We also provide the training code for face swap model as follows:

æˆ‘ä»¬è¿˜æä¾›æ¢è„¸æ¨¡å‹çš„è®­ç»ƒä»£ç å¦‚ä¸‹:

  1. Download [VGGFace2 Dataset](https://www.robots.ox.ac.uk/~vgg/data/vgg_face/).
  2. ç”¨å¤–æ£€æµ‹æ¨¡å‹è£å‰ªå’Œå¯¹é½äººè„¸ã€‚ Crop and align faces with out detection model.
  ```bash
  python preprocess_vgg.py --path_to_dataset {PATH_TO_DATASET} --save_path {SAVE_PATH}
  ```
  3. Start training. 
  ```bash
  python train.py --run_name {YOUR_RUN_NAME}
  ```
> We provide a lot of different options for the training. More info about each option you can find in `train.py` file. If you would like to use wandb logging of the experiments, you should login to wandb first  `--wandb login`.

æˆ‘ä»¬ä¸ºè®­ç»ƒæä¾›äº†å¾ˆå¤šä¸åŒçš„é€‰æ‹©ã€‚å…³äºæ¯ä¸ªé€‰é¡¹çš„æ›´å¤šä¿¡æ¯ï¼Œæ‚¨å¯ä»¥åœ¨ `train.py` ã€‚å¦‚æœä½ æƒ³ç”¨wandbè®°å½•å®éªŒï¼Œæ‚¨åº”è¯¥é¦–å…ˆç™»å½•åˆ°wandb  `--wandb login`.

### Tips
    1. å¯¹äºç¬¬ä¸€ä¸ªepochï¼Œæˆ‘ä»¬å»ºè®®ä¸è¦ä½¿ç”¨çœ¼ç›æ£€æµ‹æŸå¤±å’Œè°ƒåº¦å™¨ï¼Œå¦‚æœä½ ä»å¤´å¼€å§‹è®­ç»ƒã€‚ For the first epochs we suggest not to use eye detection loss and scheduler if you train from scratch.
    2. åœ¨è¿›è¡Œå¾®è°ƒçš„æƒ…å†µä¸‹ï¼Œæ‚¨å¯ä»¥å˜é‡æŸå¤±ç³»æ•°ï¼Œä½¿è¾“å‡ºçœ‹èµ·æ¥ä¸æºèº«ä»½ç›¸ä¼¼ï¼Œåä¹‹äº¦ç„¶ï¼Œä»¥ä¿å­˜ç›®æ ‡é¢éƒ¨çš„ç‰¹å¾å’Œå±æ€§ã€‚In case of finetuning you can variate losses coefficients to make the output look similar to the source identity, or vice versa, to save features and attributes of target face.
    3. æ‚¨å¯ä»¥ä½¿ç”¨å‚æ•°æ›´æ”¹å±æ€§ç¼–ç å™¨çš„ä¸»å¹²å’ŒAAD ResBlkçš„num_blocksã€‚You can change the backbone of the attribute encoder and num_blocks of AAD ResBlk using parameters `--backbone` and `--num_blocks`.
    4. åœ¨å¾®è°ƒé˜¶æ®µï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä½äºâ€œweightsâ€æ–‡ä»¶å¤¹ä¸­çš„ç”Ÿæˆå™¨å’Œé‰´åˆ«å™¨çš„é¢„è®­ç»ƒæƒé‡ã€‚æˆ‘ä»¬åœ¨AAD ResBlkä¸­æä¾›äº†U-Netéª¨å¹²ç½‘å’Œ1-3å—æ¨¡å‹çš„æƒé‡ã€‚ä¸»è¦æ¨¡å‹æ¶æ„åŒ…å«AAD ResBlkä¸­çš„2ä¸ªå—ã€‚During the finetuning stage you can use our pretrain weights for generator and discriminator that are located in `weights` folder. We provide the weights for models with U-Net backbone and 1-3 blocks in AAD ResBlk. The main model architecture contains 2 blocks in AAD ResBlk.

## Cite
If you use our model in your research, we would appreciate using the following citation

  ### BibTeX Citation
  ```
  @article{9851423,  
           author={Groshev, Alexander and Maltseva, Anastasia and Chesakov, Daniil and Kuznetsov, Andrey and Dimitrov, Denis},  
           journal={IEEE Access},   
           title={GHOSTâ€”A New Face Swap Approach for Image and Video Domains},   
           year={2022},  
           volume={10},  
           number={},  
           pages={83452-83462},  
           doi={10.1109/ACCESS.2022.3196668}
  }
  ```

  ### General Citation

  A. Groshev, A. Maltseva, D. Chesakov, A. Kuznetsov and D. Dimitrov, "GHOSTâ€”A New Face Swap Approach for Image and Video Domains," in IEEE Access, vol. 10, pp. 83452-83462, 2022, doi: 10.1109/ACCESS.2022.3196668.

